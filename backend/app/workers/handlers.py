from __future__ import annotations

import asyncio
from typing import Any, Iterable

from pydantic import ValidationError

from app.models.pipeline import TimelineCompositionRequest
from app.services.job_service import JobExecutionContext
from app.services.video_pipeline_service import PipelineError, VideoPipelineService
from app.utils.ffmpeg import FFmpegError

_STEP_DELAY_SECONDS = 0.25


async def _run_steps(context: JobExecutionContext, steps: Iterable[tuple[float, str]]) -> None:
    for progress, message in steps:
        await context.progress(progress, message=message)
        await asyncio.sleep(_STEP_DELAY_SECONDS)


async def ingest_handler(context: JobExecutionContext) -> dict[str, Any]:
    await context.log("Validating ingest request", payload=context.payload)
    await _run_steps(
        context,
        [
            (10.0, "Validating source media"),
            (35.0, "Copying media to staging"),
            (60.0, "Extracting technical metadata"),
            (85.0, "Registering asset in catalog"),
        ],
    )
    await context.log("Ingest processing complete")
    return {
        "asset_id": context.payload.get("asset_id"),
        "checksum": context.payload.get("checksum"),
        "notes": "Ingest pipeline completed",
    }


async def scene_detection_handler(context: JobExecutionContext) -> dict[str, Any]:
    await context.log("Initialising scene detection pipeline")
    await _run_steps(
        context,
        [
            (15.0, "Loading analysis profile"),
            (40.0, "Sampling frames"),
            (70.0, "Detecting hard cuts"),
            (90.0, "Scoring scene relevance"),
        ],
    )
    await context.log("Scene detection completed")
    scenes = [
        {"timestamp": index * 5, "confidence": 0.92} for index in range(1, 4)
    ]
    return {"scenes": scenes}


async def transcription_handler(context: JobExecutionContext) -> dict[str, Any]:
    await context.log("Preparing transcription request")
    await _run_steps(
        context,
        [
            (20.0, "Uploading audio to speech service"),
            (55.0, "Transcribing audio"),
            (80.0, "Aligning word timestamps"),
        ],
    )
    await context.log("Transcription complete")
    transcript = "This is a placeholder transcript generated by the async worker."
    return {"transcript": transcript, "language": context.payload.get("language", "en")}


def create_export_handler(pipeline_service: VideoPipelineService):
    async def export_handler(context: JobExecutionContext) -> dict[str, Any]:
        await context.log("Starting export pipeline", payload=context.payload)
        payload = context.payload or {}
        timeline_payload = payload.get("timeline") or payload
        try:
            request = TimelineCompositionRequest.model_validate(timeline_payload)
        except ValidationError as exc:
            raise PipelineError(f"Invalid timeline payload: {exc}") from exc

        async def log_callback(message: str, details: dict[str, Any]) -> None:
            await context.log(message, **details)

        async def progress_callback(value: float, message: str) -> None:
            await context.progress(value, message=message)

        try:
            result = await pipeline_service.compose_timeline(
                context.project_id,
                request,
                log=log_callback,
                progress=progress_callback,
            )
        except (PipelineError, FFmpegError) as exc:
            await context.log("Export pipeline failed", level="ERROR", error=str(exc))
            raise

        await context.log(
            "Export pipeline complete",
            exports=len(result.exports),
            proxy=bool(result.proxy),
        )
        return result.model_dump()

    return export_handler
